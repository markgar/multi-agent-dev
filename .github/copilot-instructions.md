# Copilot Instructions

## About this codebase

This software is entirely written by GitHub Copilot. The code is structured to be readable, modifiable, and extendable by Copilot (and other LLM-based agents). Every design decision should reinforce that.

### Guidelines for Copilot-friendly code

- **Flat, explicit control flow.** Prefer straightforward if/else and early returns over deeply nested logic, complex inheritance hierarchies, or metaprogramming. Every function should be understandable from its source alone.
- **Small, single-purpose functions.** Keep functions short (ideally under ~40 lines). Each function does one thing with a clear name that describes it. This gives Copilot better context boundaries.
- **Descriptive naming over comments.** Variable and function names should make intent obvious. Use comments only when *why* isn't clear from the code — never to explain *what*.
- **Colocate related logic.** Keep constants, helpers, and the code that uses them close together (or in the same small file). Avoid scattering related pieces across many modules — Copilot works best when relevant context is nearby.
- **Consistent patterns.** When multiple functions do similar things, structure them identically. Consistent shape lets Copilot reliably extend the pattern.
- **No magic.** Avoid decorators that hide behavior, dynamic attribute access, implicit registration, or monkey-patching. Everything should be traceable by reading the code top-to-bottom.
- **Simple string templates for prompts.** Keep LLM prompts as plain format strings with named placeholders. No template engines, no runtime assembly — just `.format()` or f-strings.
- **Graceful error handling.** Wrap I/O and subprocess calls in try/except. Never let a transient failure crash the orchestration loop. Log the error and continue.
- **Minimal dependencies.** Only add a dependency when it provides substantial value. Fewer deps mean less surface area for Copilot to misunderstand.
- **One concept per file.** Each module owns a single concern. Don't mix unrelated responsibilities in the same file.
- **Design for testability.** Separate pure decision logic from I/O and subprocess calls so core functions can be tested without mocking. Pass dependencies as arguments rather than hard-coding them inside functions when practical. Keep side-effect-free helpers (parsing, validation, data transforms) in their own functions so they can be unit tested directly.

## Project structure

- **Source code lives in `src/agent/`** — this is the only directory to edit.
- **`build/`** is a Python build artifact generated by setuptools/pip. Never edit files in `build/`. It is regenerated automatically and should be treated as read-only.
- **`pyproject.toml`** defines the package. The project uses a `src/` layout with the package name `agent`.

## Key files

- `src/agent/cli.py` — App definition, top-level orchestration commands: `go`, `resume`, `plan`, `status`.
- `src/agent/bootstrap.py` — Project scaffolding: repo creation, cloning reviewer/tester copies.
- `src/agent/builder.py` — Build loop: milestone completion, retry logic, reviewer drain window.
- `src/agent/watcher.py` — Commit watcher: per-commit reviews, milestone-level reviews.
- `src/agent/tester.py` — Test loop: milestone-triggered testing, final test pass.
- `src/agent/terminal.py` — Terminal spawning helper for launching agents in new windows.
- `src/agent/prompts.py` — All LLM prompt templates. Constants only, no logic.
- `src/agent/utils.py` — Core helpers: logging, command execution, platform detection.
- `src/agent/git_helpers.py` — Git operations: push with retry, commit classification.
- `src/agent/sentinel.py` — Builder-done sentinel and reviewer checkpoint persistence.
- `src/agent/milestone.py` — Milestone parsing, boundary tracking, and per-agent milestone checkpoints.
- `src/agent/config.py` — Language/stack configurations and prerequisites.

## Architecture

This is a multi-agent orchestrator that uses GitHub Copilot CLI (`copilot --yolo`) as the execution engine. Agents (builder, planner, reviewer, tester) run as separate processes in separate git clones of the same repo. They coordinate through:

- **Markdown files** (`TASKS.md`, `BUGS.md`, `REVIEWS.md`) — shared state via git push/pull.
- **Log files** (`logs/`) — local coordination signals like `builder.done`, `reviewer.checkpoint`, `milestones.log`.

The build loop (Python code in `builder.py`) handles deterministic orchestration — milestone boundary tracking, SHA recording, shutdown signals. The LLM agents handle creative work — writing code, reviewing diffs, writing tests.

## Testing conventions

- **Tests live in `tests/`** mirroring `src/agent/` — e.g. `tests/test_milestone.py` tests `agent.milestone`.
- **Use pytest.** No unittest classes. Plain functions with descriptive names.
- **Test the contract, not the implementation.** A test should describe expected behavior in terms a user would understand — not mirror the code's internal branching. If the test would break when you refactor internals without changing behavior, it's too tightly coupled.
- **Name tests as behavioral expectations.** `test_stuck_milestone_stops_after_three_retries` not `test_update_milestone_retry_state_returns_true`. The test name should read like a requirement.
- **Use realistic inputs.** Feed a real-looking TASKS.md with multiple milestones, not a minimal one-line synthetic string. Edge cases should be things that could actually happen — corrupted log lines, empty files, milestones with zero tasks.
- **Prefer regression tests.** When a bug is found, write the test that would have caught it before fixing it. This is the highest-value test you can write.
- **Don't test I/O wrappers.** Functions that just read a file and call a pure helper don't need their own tests — test the pure helper directly. Functions that just call subprocess don't need unit tests — they're validated by integration/end-to-end runs.
- **No mocking unless unavoidable.** The pure functions extracted for testability exist specifically so you don't need mocks. If you find yourself mocking, consider whether you should be testing a different function.

## Conventions

- Agent prompts are append-only format strings in `prompts.py`. Use `.format()` for interpolation.
- All file I/O helpers in `utils.py` wrap operations in try/except and never crash the workflow over I/O errors.
- `resolve_logs_dir()` finds the project-root `logs/` directory regardless of which clone (builder/reviewer/tester) the code is running in.
